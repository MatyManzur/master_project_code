{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import os, glob\n",
    "\n",
    "def download_dataset(api_key: str, workspace: str, project: str, version: int):\n",
    "    rf = Roboflow(api_key=api_key)\n",
    "    dataset = rf.workspace(workspace).project(project).version(version).download(\"yolov8\")\n",
    "    return dataset\n",
    "\n",
    "dataset = download_dataset(api_key=\"K0xg5GEEinqPgaqjKKzz\", workspace=\"matyworkspace\", project=\"damagedhealthytrafficsigns\", version=9)\n",
    "\n",
    "image_dir = os.path.join(dataset.location, \"test\", \"images\")\n",
    "label_dir = os.path.join(dataset.location, \"test\", \"labels\")\n",
    "image_paths = glob.glob(os.path.join(image_dir, \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_predictions import save_predictions_to_file\n",
    "\n",
    "predictions_file = \"predictions.json\"\n",
    "if not os.path.exists(predictions_file):\n",
    "    save_predictions_to_file(image_paths, predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_predictions import process_all_predictions\n",
    "\n",
    "processed_predictions_file = \"none.json\"\n",
    "if not os.path.exists(processed_predictions_file):\n",
    "    process_all_predictions(image_paths, predictions_file, label_dir, processed_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98534ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30656107",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"none.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "classes = ['healthy', 'damaged', 'background']\n",
    "y_true = df['actual']\n",
    "y_pred = df['predicted_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "\n",
    "display(cm_df)\n",
    "\n",
    "#cm[2, 2] = 0  # Set background-background to nan\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Only use 'healthy' and 'damaged' classes\n",
    "labels = ['healthy', 'damaged']\n",
    "precision = precision_score(df['actual'], df['predicted_label'], average=None, labels=labels)\n",
    "recall = recall_score(df['actual'], df['predicted_label'], average=None, labels=labels)\n",
    "f1 = f1_score(df['actual'], df['predicted_label'], average=None, labels=labels)\n",
    "\n",
    "for cls, p, r, f in zip(labels, precision, recall, f1):\n",
    "    print(f\"{cls}: Precision={p:.3f}, Recall={r:.3f}, F1={f:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91484fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "ious = np.arange(0.5, 1.0, 0.05)\n",
    "aps = []\n",
    "\n",
    "for iou_thr in ious:\n",
    "    # Filter detections by IoU threshold\n",
    "    df_iou = df.copy()\n",
    "\n",
    "    # AP for healthy\n",
    "    y_true_healthy = (df_iou['actual'] == 'healthy').astype(int)\n",
    "    y_score_healthy = df_iou['confidence'] * df_iou['score'] * (df_iou['iou'] >= iou_thr).astype(float) * (df_iou['score'] >= 0.5).astype(float)\n",
    "    ap_healthy = average_precision_score(y_true_healthy, y_score_healthy) if len(y_true_healthy) > 0 and y_true_healthy.sum() > 0 else np.nan\n",
    "\n",
    "    # AP for damaged\n",
    "    y_true_damaged = (df_iou['actual'] == 'damaged').astype(int)\n",
    "    y_score_damaged = df_iou['confidence'] * (1 - df_iou['score']) * (df_iou['iou'] >= iou_thr).astype(float) * (df_iou['score'] <= 0.5).astype(float)\n",
    "    ap_damaged = average_precision_score(y_true_damaged, y_score_damaged) if len(y_true_damaged) > 0 and y_true_damaged.sum() > 0 else np.nan\n",
    "\n",
    "    aps.append({'iou': iou_thr, 'AP_healthy': ap_healthy, 'AP_damaged': ap_damaged})\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "aps_df = pd.DataFrame(aps)\n",
    "aps_df['mAP'] = aps_df[['AP_healthy', 'AP_damaged']].mean(axis=1)\n",
    "display(aps_df)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(aps_df['iou'], aps_df['AP_healthy'], label='AP Healthy', marker='o', color='green')\n",
    "plt.plot(aps_df['iou'], aps_df['AP_damaged'], label='AP Damaged', marker='o', color='red')\n",
    "plt.plot(aps_df['iou'], aps_df['mAP'], label='mAP', marker='o', color='blue')\n",
    "plt.xlabel('IoU Threshold')\n",
    "plt.ylabel('Average Precision (AP)')\n",
    "plt.title('AP and mAP vs IoU Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular mAP@50:95 (media de mAP para IoU de 0.50 a 0.95 con paso 0.05)\n",
    "map_50_95 = aps_df['mAP'].mean()\n",
    "print(f\"mAP@50:95 = {map_50_95:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
