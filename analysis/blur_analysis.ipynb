{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import os, glob\n",
    "from visualization import show_random_images_with_bboxes\n",
    "\n",
    "def download_dataset(api_key: str, workspace: str, project: str, version: int):\n",
    "    rf = Roboflow(api_key=api_key)\n",
    "    dataset = rf.workspace(workspace).project(project).version(version).download(\"yolov8\")\n",
    "    return dataset\n",
    "\n",
    "dataset = download_dataset(api_key=\"K0xg5GEEinqPgaqjKKzz\", workspace=\"matyworkspace\", project=\"damagedhealthytrafficsigns\", version=9)\n",
    "\n",
    "image_dir = os.path.join(dataset.location, \"test\", \"images\")\n",
    "label_dir = os.path.join(dataset.location, \"test\", \"labels\")\n",
    "image_paths = glob.glob(os.path.join(image_dir, \"*.jpg\"))\n",
    "\n",
    "#show_random_images_with_bboxes(image_paths, label_dir, N=8, cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c80753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blur_levels = [0, 0.5, 1.0, 2.0, 4.0]\n",
    "blur_levels = [0.1, 0.2, 0.35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_modification import create_property_groups_relative\n",
    "import json\n",
    "\n",
    "output_base_dir = dataset.location\n",
    "blur_groups = create_property_groups_relative(output_base_dir, image_paths, 'blur', blur_levels)\n",
    "\n",
    "\n",
    "with open(\"blur_groups.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(blur_groups, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b028c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "blur_groups = json.load(open(\"blur_groups.json\", \"r\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_predictions import save_predictions_to_file\n",
    "import os\n",
    "\n",
    "for group_name, group_data in blur_groups.items():\n",
    "    print(f\"Group: {group_name}, Number of images: {len(group_data['images'])}\")\n",
    "    predictions_file = f\"predictions_blur_{group_name}.json\"\n",
    "    if not os.path.exists(predictions_file):\n",
    "        save_predictions_to_file([img['modified_path'] for img in group_data['images']], predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_predictions import process_all_predictions\n",
    "import os\n",
    "\n",
    "for group_name, group_data in blur_groups.items():\n",
    "    predictions_file = f\"predictions_blur_{group_name}.json\"\n",
    "    processed_predictions_file = f\"processed_predictions_blur_{group_name}.json\"\n",
    "    if not os.path.exists(processed_predictions_file):\n",
    "        image_paths = [img['modified_path'] for img in group_data['images']]\n",
    "        process_all_predictions(image_paths, predictions_file, label_dir, processed_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98534ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from group_metrics_calculation import calculate_metrics_for_group_relative\n",
    "for group_name, group_data in blur_groups.items():\n",
    "    processed_predictions_file = f\"processed_predictions_blur_{group_name}.json\"\n",
    "    with open(processed_predictions_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    blur_groups[group_name]['metrics'] = calculate_metrics_for_group_relative(df)\n",
    "    print(f\"Metrics for group {group_name}: {blur_groups[group_name]['metrics']}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "property_name = 'blur'\n",
    "metrics_to_plot = ['precision_healthy', 'precision_damaged', 'recall_healthy', 'recall_damaged', \n",
    "                   'f1_healthy', 'f1_damaged', 'mAP_50', 'mAP_50_95']\n",
    "metric_labels = ['Precision Healthy', 'Precision Damaged', 'Recall Healthy', 'Recall Damaged', \n",
    "                 'F1 Healthy', 'F1 Damaged', 'mAP@0.5', 'mAP@0.5:0.95']\n",
    "\n",
    "property_values = []\n",
    "metrics_data = {metric: [] for metric in metrics_to_plot}\n",
    "group_names = []\n",
    "\n",
    "for group_name, group_data in blur_groups.items():\n",
    "    property_values.append(group_data['relative_change'])\n",
    "    group_names.append(group_name)\n",
    "    \n",
    "    for metric in metrics_to_plot:\n",
    "        metrics_data[metric].append(group_data['metrics'][metric])\n",
    "\n",
    "sorted_indices = np.argsort(property_values)\n",
    "property_values = np.array(property_values)[sorted_indices]\n",
    "group_names = np.array(group_names)[sorted_indices]\n",
    "\n",
    "for i, (metric, label) in enumerate(zip(metrics_to_plot, metric_labels)):\n",
    "    metric_values = np.array(metrics_data[metric])[sorted_indices]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(property_values, metric_values, \n",
    "                 fmt='o-', capsize=5, capthick=2, linewidth=1)\n",
    "    \n",
    "    for j, (x, y) in enumerate(zip(property_values, metric_values)):\n",
    "        plt.annotate(f'{y:.3f}', (x, y), textcoords=\"offset points\", xytext=(0,15), \n",
    "                    ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    y_margin = (metric_values.max() - metric_values.min()) * 0.15\n",
    "    plt.ylim(metric_values.min() - y_margin, metric_values.max() + y_margin)\n",
    "    \n",
    "    plt.xlabel(property_name.title())\n",
    "    plt.ylabel(label)\n",
    "    plt.title(f'{label} vs {property_name.title()}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d30adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from models import ObjectPrediction\n",
    "PROPERTY = 'blur'\n",
    "GROUPS = ['blur_rel_+0.10', 'blur_rel_+0.20', 'blur_rel_+0.35', 'blur_rel_+0.50', 'blur_rel_+1.00', 'blur_rel_+2.00', 'blur_rel_+4.00']\n",
    "\n",
    "ppredictions_original_file = \"none.json\"\n",
    "ppredictions_original: dict[str, list[ObjectPrediction]] = {}\n",
    "\n",
    "with open(ppredictions_original_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for item in json.load(f):\n",
    "        image_path = item['image']\n",
    "        if image_path not in ppredictions_original:\n",
    "            ppredictions_original[image_path] = []\n",
    "        ppredictions_original[image_path].append(ObjectPrediction.from_dict(item))\n",
    "\n",
    "blur_groups = json.load(open(\"blur_groups.json\", \"r\", encoding=\"utf-8\"))\n",
    "combined_predictions = {}\n",
    "\n",
    "for group in GROUPS:    \n",
    "\n",
    "    ppredictions_modified_file = f\"processed_predictions_{PROPERTY}_{group}.json\"\n",
    "    ppredictions_modified: dict[str, list[ObjectPrediction]] = {}\n",
    "\n",
    "    with open(ppredictions_modified_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for item in json.load(f):\n",
    "            image_path = item['image']\n",
    "            if image_path not in ppredictions_modified:\n",
    "                ppredictions_modified[image_path] = []\n",
    "            ppredictions_modified[image_path].append(ObjectPrediction.from_dict(item))\n",
    "    \n",
    "    blur_group = blur_groups[group]\n",
    "\n",
    "    for img in blur_group['images']:\n",
    "        original_path = img['original_path']\n",
    "        modified_path = img['modified_path']\n",
    "        orig_preds = ppredictions_original.get(original_path, [])\n",
    "        mod_preds = ppredictions_modified.get(modified_path, [])\n",
    "        objects = {}\n",
    "        for pred in orig_preds:\n",
    "            key = pred.actual_bbox.__str__() if pred.actual_bbox is not None else pred.predicted_bbox.__str__()\n",
    "            objects[key] = {\n",
    "                'gt': (pred.actual, pred.actual_bbox.to_dict() if pred.actual_bbox else None),\n",
    "                'original_pred': (pred.predicted_label, pred.predicted_bbox.to_dict() if pred.predicted_bbox else None),\n",
    "            }\n",
    "        for pred in mod_preds:\n",
    "            key = pred.actual_bbox.__str__() if pred.actual_bbox is not None else pred.predicted_bbox.__str__()\n",
    "            if key in objects:\n",
    "                objects[key]['modified_pred'] = (pred.predicted_label, pred.predicted_bbox.to_dict() if pred.predicted_bbox else None)\n",
    "            else:\n",
    "                objects[key] = {\n",
    "                    'gt': (pred.actual, pred.actual_bbox.to_dict() if pred.actual_bbox else None),\n",
    "                    'modified_pred': (pred.predicted_label, pred.predicted_bbox.to_dict() if pred.predicted_bbox else None),\n",
    "                }\n",
    "        image_combined_predictions = {\n",
    "            'original_path': original_path,\n",
    "            'modified_path': modified_path,\n",
    "            'objects': list(objects.values()),\n",
    "            'property_change': blur_group['relative_change']\n",
    "        }\n",
    "        original_false_detections = 0\n",
    "        modified_false_detections = 0\n",
    "        reduced_false_backgrounds = 0\n",
    "        added_false_backgrounds = 0\n",
    "        reduced_misclassifications = 0\n",
    "        added_misclassifications = 0\n",
    "        for obj in image_combined_predictions['objects']:\n",
    "            gt_label = obj['gt'][0]\n",
    "            original_label = obj.get('original_pred', ('background', None))[0]\n",
    "            modified_label = obj.get('modified_pred', ('background', None))[0]\n",
    "            if gt_label == 'background':\n",
    "                if original_label != 'background':\n",
    "                    original_false_detections += 1\n",
    "                if modified_label != 'background':\n",
    "                    modified_false_detections += 1\n",
    "            else:\n",
    "                if original_label == 'background' and modified_label == gt_label:\n",
    "                    reduced_false_backgrounds += 1\n",
    "                if original_label == gt_label and modified_label == 'background':\n",
    "                    added_false_backgrounds += 1\n",
    "                if original_label != gt_label and original_label != 'background' and modified_label == gt_label:\n",
    "                    reduced_misclassifications += 1\n",
    "                if original_label == gt_label and modified_label != gt_label and modified_label != 'background':\n",
    "                    added_misclassifications += 1\n",
    "        combined_predictions[f\"{blur_group['relative_change']}_{original_path}\"] = {\n",
    "            **image_combined_predictions,\n",
    "            'original_false_detections': original_false_detections,\n",
    "            'modified_false_detections': modified_false_detections,\n",
    "            'reduced_false_backgrounds': reduced_false_backgrounds,\n",
    "            'added_false_backgrounds': added_false_backgrounds,\n",
    "            'reduced_misclassifications': reduced_misclassifications,\n",
    "            'added_misclassifications': added_misclassifications,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb10ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dfc = pd.DataFrame(combined_predictions).T\n",
    "\n",
    "grouped_data = dfc.groupby('property_change').agg({\n",
    "    'original_false_detections': 'sum',\n",
    "    'modified_false_detections': 'sum',\n",
    "    'reduced_false_backgrounds': 'sum',\n",
    "    'added_false_backgrounds': 'sum',\n",
    "    'reduced_misclassifications': 'sum',\n",
    "    'added_misclassifications': 'sum',\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ce32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_2(grouped_data, title, y_title, neg_key, pos_key, pos_color='green'):\n",
    "    # Create the bar plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    x = np.arange(len(grouped_data) + 1)\n",
    "    width = 0.35\n",
    "\n",
    "    bar_keys = ['0'] + list(grouped_data['property_change'])\n",
    "    bar_heights = [grouped_data[neg_key][0]] + [x for x in grouped_data[pos_key]]\n",
    "\n",
    "\n",
    "    bars1 = ax.bar(x, bar_heights, width, \n",
    "                alpha=0.8, color=pos_color)\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Blur')\n",
    "    ax.set_ylabel(y_title)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(bar_keys)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    def add_value_labels(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax.annotate(f'{int(height)}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    add_value_labels(bars1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_grouped_data(grouped_data, title, y_title, neg_key, pos_key, neg_label, pos_label, neg_color='red', pos_color='green'):\n",
    "    # Create the bar plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    x = np.arange(len(grouped_data))\n",
    "    width = 0.35\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, grouped_data[neg_key], width, \n",
    "                label=neg_label, alpha=0.8, color=neg_color)\n",
    "    bars2 = ax.bar(x + width/2, grouped_data[pos_key], width, \n",
    "                label=pos_label, alpha=0.8, color=pos_color)\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Blur')\n",
    "    ax.set_ylabel(y_title)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(grouped_data['property_change'])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    def add_value_labels(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax.annotate(f'{int(height)}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    add_value_labels(bars1)\n",
    "    add_value_labels(bars2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_2(grouped_data, \n",
    "                  title='False Detections vs Blur', \n",
    "                  y_title='Total False Detections',\n",
    "                  neg_key='original_false_detections', \n",
    "                  pos_key='modified_false_detections', \n",
    "                  pos_color='blue')\n",
    "\n",
    "plot_grouped_data(grouped_data,\n",
    "                title='Change in False Backgrounds vs Blur', \n",
    "                y_title='False Backgrounds',\n",
    "                neg_key='added_false_backgrounds', \n",
    "                pos_key='reduced_false_backgrounds', \n",
    "                neg_label='Added False Backgrounds', \n",
    "                pos_label='Reduced False Backgrounds', \n",
    "                neg_color='red', \n",
    "                pos_color='green')\n",
    "\n",
    "plot_grouped_data(grouped_data,\n",
    "                title='Change in Misclassifications vs Blur', \n",
    "                y_title='Misclassifications',\n",
    "                neg_key='added_misclassifications', \n",
    "                pos_key='reduced_misclassifications', \n",
    "                neg_label='Added Misclassifications', \n",
    "                pos_label='Reduced Misclassifications', \n",
    "                neg_color='red', \n",
    "                pos_color='green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
