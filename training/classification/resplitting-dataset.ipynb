{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-11T15:04:50.609101Z",
     "iopub.status.busy": "2025-06-11T15:04:50.608409Z",
     "iopub.status.idle": "2025-06-11T15:04:58.292172Z",
     "shell.execute_reply": "2025-06-11T15:04:58.291242Z",
     "shell.execute_reply.started": "2025-06-11T15:04:50.609075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!curl -L \"https://app.roboflow.com/ds/RolsO4e05e?key=OgTkpJ7f0p\" > roboflow.zip; unzip -q roboflow.zip; rm roboflow.zip\n",
    "! rm README.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T10:55:09.815476Z",
     "iopub.status.busy": "2025-06-11T10:55:09.814364Z",
     "iopub.status.idle": "2025-06-11T10:55:09.821755Z",
     "shell.execute_reply": "2025-06-11T10:55:09.820510Z",
     "shell.execute_reply.started": "2025-06-11T10:55:09.815443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, math, random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T11:45:55.830105Z",
     "iopub.status.busy": "2025-06-11T11:45:55.829748Z",
     "iopub.status.idle": "2025-06-11T11:45:55.836216Z",
     "shell.execute_reply": "2025-06-11T11:45:55.835137Z",
     "shell.execute_reply.started": "2025-06-11T11:45:55.830079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SOURCE_DIR = './train/' \n",
    "DEST_DIR = 'split_dataset'\n",
    "CLASSES = ['ok', 'not_ok']\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "IMG_SIZE = (INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
    "NUM_CLUSTERS = 20\n",
    "SPLIT_RATIOS = {\n",
    "    'train': 0.75,\n",
    "    'valid': 0.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T10:20:10.947986Z",
     "iopub.status.busy": "2025-06-11T10:20:10.947455Z",
     "iopub.status.idle": "2025-06-11T10:20:14.090563Z",
     "shell.execute_reply": "2025-06-11T10:20:14.089704Z",
     "shell.execute_reply.started": "2025-06-11T10:20:10.947947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T11:43:55.917046Z",
     "iopub.status.busy": "2025-06-11T11:43:55.916669Z",
     "iopub.status.idle": "2025-06-11T11:43:55.934983Z",
     "shell.execute_reply": "2025-06-11T11:43:55.933778Z",
     "shell.execute_reply.started": "2025-06-11T11:43:55.917024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def extract_embeddings(image_paths):\n",
    "    embeddings = []\n",
    "    for img_path in tqdm(image_paths, desc=\"Extracting embeddings\"):\n",
    "        img_array = load_and_preprocess_image(img_path)\n",
    "        embedding = model.predict(img_array, verbose=0)\n",
    "        embeddings.append(embedding[0])\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def split_by_cluster(clustered_images, output_dir, cluster_groups, problem_cluster_groups):\n",
    "    for split in SPLIT_RATIOS:\n",
    "        for cls in CLASSES:\n",
    "            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n",
    "\n",
    "    discarded = {\n",
    "        'ok': [],\n",
    "        'not_ok': []\n",
    "    }\n",
    "    to_train = {\n",
    "        'ok': [],\n",
    "        'not_ok': []\n",
    "    }\n",
    "    to_valid = {\n",
    "        'ok': [],\n",
    "        'not_ok': []\n",
    "    }\n",
    "\n",
    "    for group in cluster_groups:\n",
    "        cluster = []\n",
    "        idx = \"\"\n",
    "        for cidx in group:\n",
    "            cluster.extend(clustered_images[cidx])\n",
    "            idx += f\"{cidx} \"\n",
    "        \n",
    "        ok_cluster = []\n",
    "        not_ok_cluster = []\n",
    "        for img_path in cluster:\n",
    "            if 'not_ok' in img_path:\n",
    "                not_ok_cluster.append(img_path)\n",
    "            else:\n",
    "                ok_cluster.append(img_path)\n",
    "        random.shuffle(ok_cluster)\n",
    "        random.shuffle(not_ok_cluster)\n",
    "        ok_split_index = int(len(ok_cluster)*SPLIT_RATIOS['train'])\n",
    "        not_ok_split_index = int(len(not_ok_cluster)*SPLIT_RATIOS['train'])\n",
    "        to_train['ok'].extend(ok_cluster[:ok_split_index])\n",
    "        to_train['not_ok'].extend(not_ok_cluster[:not_ok_split_index])\n",
    "        to_valid['ok'].extend(ok_cluster[ok_split_index:])\n",
    "        to_valid['not_ok'].extend(not_ok_cluster[not_ok_split_index:])\n",
    "        print(f\"Spliting regular cluster {idx}: found {len(ok_cluster)} ok, {len(not_ok_cluster)} not_ok. Keeping {len(ok_cluster) + len(not_ok_cluster)}, discarding {0}\")\n",
    "\n",
    "    for group in problem_cluster_groups:\n",
    "        cluster = []\n",
    "        idx = \"\"\n",
    "        for cidx in group:\n",
    "            cluster.extend(clustered_images[cidx])\n",
    "            idx += f\"{cidx} \"\n",
    "        \n",
    "        ok_cluster = []\n",
    "        not_ok_cluster = []\n",
    "        for img_path in cluster:\n",
    "            if 'not_ok' in img_path:\n",
    "                not_ok_cluster.append(img_path)\n",
    "            else:\n",
    "                ok_cluster.append(img_path)\n",
    "        random.shuffle(ok_cluster)\n",
    "        random.shuffle(not_ok_cluster)\n",
    "        \n",
    "        balanced_min = min(len(ok_cluster), len(not_ok_cluster))\n",
    "        split_index = int(balanced_min * SPLIT_RATIOS['train'])\n",
    "\n",
    "        to_train['ok'].extend(ok_cluster[:split_index])\n",
    "        to_train['not_ok'].extend(not_ok_cluster[:split_index])\n",
    "        to_valid['ok'].extend(ok_cluster[split_index:balanced_min])\n",
    "        to_valid['not_ok'].extend(not_ok_cluster[split_index:balanced_min])\n",
    "    \n",
    "        discarded['ok'].extend(ok_cluster[balanced_min:])\n",
    "        discarded['not_ok'].extend(not_ok_cluster[balanced_min:])\n",
    "        print(f\"Spliting problem cluster {idx}: found {len(ok_cluster)} ok, {len(not_ok_cluster)} not_ok. Keeping {2*balanced_min}, discarding {len(ok_cluster) - balanced_min + len(not_ok_cluster) - balanced_min}\")\n",
    "            \n",
    "            \n",
    "    split_count = {\n",
    "        'train': [0,0],\n",
    "        'valid': [0,0]\n",
    "    }\n",
    "    for split in ['train', 'valid']:\n",
    "        split_dict = to_train if split=='train' else to_valid\n",
    "        for cls, imgs in split_dict.items():\n",
    "            for img_path in imgs:\n",
    "                dest_path = os.path.join(output_dir, split, cls, os.path.basename(img_path))\n",
    "                shutil.copy2(img_path, dest_path)\n",
    "                split_count[split][0 if cls=='not_ok' else 1] += 1\n",
    "\n",
    "    print(f\"{'Split':<10} {'NOT_OK':>10} {'OK':>10} {'Ratio':>10}\")\n",
    "    print('-' * (44))\n",
    "    for split, counts in split_count.items():\n",
    "        print(f\"{split:<10} {counts[0]:>10} {counts[1]:>10} {counts[0]/counts[1]:>10.2f}\")\n",
    "    print()\n",
    "    print(f\"Total discarded: {len(discarded['ok']) + len(discarded['not_ok'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T10:20:14.109167Z",
     "iopub.status.busy": "2025-06-11T10:20:14.108797Z",
     "iopub.status.idle": "2025-06-11T10:30:44.915053Z",
     "shell.execute_reply": "2025-06-11T10:30:44.913949Z",
     "shell.execute_reply.started": "2025-06-11T10:20:14.109132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load all image paths\n",
    "all_image_paths = []\n",
    "for cls in CLASSES:\n",
    "    class_dir = os.path.join(SOURCE_DIR, cls)\n",
    "    image_paths = [os.path.join(class_dir, fname) for fname in os.listdir(class_dir)\n",
    "                   if fname.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "    all_image_paths.extend(image_paths)\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = extract_embeddings(all_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T11:19:05.257189Z",
     "iopub.status.busy": "2025-06-11T11:19:05.256867Z",
     "iopub.status.idle": "2025-06-11T11:19:11.079364Z",
     "shell.execute_reply": "2025-06-11T11:19:11.078361Z",
     "shell.execute_reply.started": "2025-06-11T11:19:05.257165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cluster with KMeans\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(embeddings)\n",
    "distinct_labels = set(cluster_labels)\n",
    "\n",
    "# Group images by cluster\n",
    "clustered_images = {label: [] for label in distinct_labels}\n",
    "for idx, label in enumerate(cluster_labels):\n",
    "    clustered_images[label].append(all_image_paths[idx])\n",
    "\n",
    "print(f\"Divided into {len(distinct_labels)} clusters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T11:49:28.071633Z",
     "iopub.status.busy": "2025-06-11T11:49:28.071224Z",
     "iopub.status.idle": "2025-06-11T11:51:34.520401Z",
     "shell.execute_reply": "2025-06-11T11:51:34.518942Z",
     "shell.execute_reply.started": "2025-06-11T11:49:28.071602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SAMPLES = 180\n",
    "SAMPLES_PER_ROW = 20\n",
    "for cluster_id, paths in clustered_images.items():\n",
    "    not_ok_count = sum(1 if 'not_ok' in path else 0 for path in paths)\n",
    "    ok_count = len(paths) - not_ok_count\n",
    "    ratio = max(ok_count, not_ok_count) / min(ok_count, not_ok_count)\n",
    "    print(f\"\\nCluster {cluster_id} ({len(paths)} images) ({not_ok_count} damaged) ({ok_count} ok) - {ratio}\")\n",
    "    sample_paths = (random.sample(paths,SAMPLES)) if SAMPLES <= len(paths) else paths\n",
    "    num_images = len(sample_paths)\n",
    "    cols = min(SAMPLES_PER_ROW, num_images)  # Maximum 5 images per row\n",
    "    rows = math.ceil(num_images / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=( cols, rows))\n",
    "    axes = axes.flatten() if num_images > 1 else [axes]\n",
    "    for ax, img_path in zip(axes, sample_paths):\n",
    "        img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T11:46:44.610661Z",
     "iopub.status.busy": "2025-06-11T11:46:44.610318Z",
     "iopub.status.idle": "2025-06-11T11:46:45.036439Z",
     "shell.execute_reply": "2025-06-11T11:46:45.035579Z",
     "shell.execute_reply.started": "2025-06-11T11:46:44.610631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "split_by_cluster(\n",
    "    clustered_images, \n",
    "    DEST_DIR, \n",
    "    cluster_groups=[[2], [3], [6], [7], [18], [19]], \n",
    "    problem_cluster_groups=[[0], [1], [4,9], [5,8], [10], [11], [12, 16], [17]]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
